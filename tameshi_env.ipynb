{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "meaningful-resolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def transform_2d(target_x, target_y, target_yaw, origin_x, origin_y, origin_yaw):\n",
    "    t_mat = np.identity(3)\n",
    "    t_mat[:2,2] = [-origin_x, -origin_y]\n",
    "    r_mat = np.array([\n",
    "                [np.cos(-origin_yaw), -np.sin(-origin_yaw), 0],\n",
    "                [np.sin(-origin_yaw), np.cos(-origin_yaw), 0],\n",
    "                [0, 0, 1]\n",
    "            ])\n",
    "    af = np.dot(r_mat, t_mat)\n",
    "    target_xy = np.array([target_x, target_y, 1])\n",
    "    transed_xy = np.dot(af, target_xy)\n",
    "    \n",
    "    return transed_xy[0], transed_xy[1], target_yaw - origin_yaw\n",
    "\n",
    "def cartesian_to_polar_2d(x, y):\n",
    "    return np.norm.linalg([x,y]), np.arctan2(y,x)\n",
    "\n",
    "def polar_to_cartesian_2d(r, theta):\n",
    "    return r*np.cos(theta), r*np.sin(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "frequent-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time, math, copy\n",
    "import numpy as np\n",
    "import gym\n",
    "from gym import spaces, logger\n",
    "from gym.utils import seeding\n",
    "\n",
    "from robo_gym.utils import utils\n",
    "from robo_gym.utils.exceptions import InvalidStateError, RobotServerError\n",
    "import robo_gym_server_modules.robot_server.client as rs_client\n",
    "from robo_gym.envs.simulation_wrapper import Simulation\n",
    "from robo_gym_server_modules.robot_server.grpc_msgs.python import robot_server_pb2\n",
    "\n",
    "from typing import List\n",
    "\n",
    "class Mir100Env(gym.Env):\n",
    "    real_robot = False\n",
    "    map_size = 256\n",
    "    resolution = 0.05\n",
    "    \n",
    "    def __init__(self, rs_address=None, max_episode_steps=500, **kwargs):\n",
    "        self.mir100 = mir100_util.Mir100()\n",
    "        self.max_episde_steps = max_episode_steps\n",
    "        self.elapsed_steps = 0\n",
    "        \n",
    "        self.observation_space = self._get_observation_space()\n",
    "        \n",
    "#         self.action_space = spaces.Dict({\n",
    "#             'polar_r': spaces.Box(low=0, high=1, shape=(2,)),\n",
    "#             'polar_theta': spaces.Box(low=-1, high=1, shape=(2,)),\n",
    "#             'yaw': spaces.Box(low=-1, high=1, shape=(2, ))\n",
    "#         })\n",
    "        \n",
    "#         self.action_space = spaces.Dict({\n",
    "#             'position': spaces.Box(low=-half, high=half, shape=(2,), dtype=np.float32),\n",
    "#             'orientation': spaces.Box(low=0, high=np.pi*2, dtype=np.float32)\n",
    "#         })\n",
    "\n",
    "        self.seed()\n",
    "        self.distance_threshold = 0.2\n",
    "        self.min_target_dist = 1.0\n",
    "        \n",
    "        half = map_size*resolution/2\n",
    "        self.movable_range = half/2\n",
    "        \n",
    "        self.action_space = spaces.Box(low=np.array([0,-1,-1]), high=np.array([1,1,1]))\n",
    "        self.action_range = np.array([self.movable_range, np.pi, np.pi])\n",
    "        \n",
    "        self.map_trueth = []\n",
    "        self.start_frame = [0,0,0] # initial pose [x,y,yaw] in world frame when started episode \n",
    "        self.agent_pose = [0,0,0] # now pose [x,y,yaw] in map frame\n",
    "        self.target_num = 0\n",
    "        self.target_pose = [] # target poses [[x,y,yaw],] in world frame\n",
    "        \n",
    "        # Connect to Robot Server\n",
    "        if rs_address:\n",
    "            self.client = rs_client.Client(rs_address)\n",
    "        else:\n",
    "            print(\"WARNING: No IP and Port passed. Simulation will not be started\")\n",
    "            print(\"WARNING: Use this only to get environment shape\")\n",
    "            \n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "    \n",
    "    def reset(self, \n",
    "              new_room: bool,\n",
    "              new_agent_pose: bool, \n",
    "              obstacle_count: int=10, \n",
    "              obstacle_size: float=0.7, \n",
    "              target_size: float=0.2, \n",
    "              room_length_max: float=9.0, \n",
    "              room_mass_min: float=20.0, \n",
    "              room_mass_max: float=36.0, \n",
    "              room_wall_height: float=0.8, \n",
    "              room_wall_thickness: float=0.05,\n",
    "              target_poses:List[List[float]]=None):\n",
    "        \n",
    "        \"\"\"Environment reset\n",
    "        \n",
    "        Args:\n",
    "            new_room (bool): is generate new room when initialize Environment\n",
    "            new_agent_pose (bool): is change pose in the room when initialize Environment\n",
    "        \"\"\"\n",
    "        \n",
    "        self.elapsed_steps = 0\n",
    "        self.prev_base_reward = None\n",
    "        \n",
    "        # Initialize environment state\n",
    "        self.state = {}\n",
    "        rs_state = np.zeros(self._get_robot_server_state_len())\n",
    "        \n",
    "        ignore_start = 1\n",
    "        map_state_len = (self.map_size**2)*2\n",
    "        ignore_len = map_state_len + 6\n",
    "        ignore_index = ignore_start + ignore_len\n",
    "        \n",
    "        rs_state[0] = self.map_size\n",
    "        rs_state[ignore_index] = new_room\n",
    "        rs_state[ignore_index+1] = new_agent_pose\n",
    "        rs_state[ignore_index+2] = obstacle_count\n",
    "        rs_state[ignore_index+3] = obstacle_size\n",
    "        rs_state[ignore_index+4] = target_size\n",
    "        rs_state[ignore_index+5] = room_length_max\n",
    "        rs_state[ignore_index+6] = room_mass_min\n",
    "        rs_state[ignore_index+7] = room_mass_max\n",
    "        rs_state[ignore_index+8] = room_wall_thickness\n",
    "        \n",
    "        state_msg = robot_server_pb2.State(state=rs_state.tolist())\n",
    "        if not self.client.set_state_msg(state_msg):\n",
    "            raise RobotServerError(\"set_state\")\n",
    "            \n",
    "        # Get Robot Server state\n",
    "        rs_state = copy.deepcopy(np.array(self.client.get_state_msg().state))\n",
    "\n",
    "        # in World frame\n",
    "        self.start_frame = rs_state[1+map_state_len : 1+map_state_len+3]\n",
    "        \n",
    "        self.target_num = len(rs_state[ignore_index+9:])//3\n",
    "        if len(rs_state[ignore_index+9:]) % 3 != 0:\n",
    "            raise Exception(\"wrong length of targets in robot server state\")\n",
    "            \n",
    "        self.agent_pose = np.array([0, 0, 0]) # [x,y,yaw] pose in map frame\n",
    "        self.target_pose = np.reshape(rs_state[ignore_index+9:], [self.target_num, 3])\n",
    "        self.agent_twist = rs_state[2+map_state_len : 2+map_state_len+2]\n",
    "        self.map_trueth = rs_state[1+self.map_size**2 : 1+map_state_len]\n",
    "        \n",
    "        self.state = self._robot_server_state_to_env_state(rs_state)\n",
    "\n",
    "        # Check if the environment state is contained in the observation space\n",
    "        if not self.observation_space.contains(self.state):\n",
    "            raise InvalidStateError()\n",
    "            \n",
    "        return self.state\n",
    "    \n",
    "    def _reward(self, rs_state, action):\n",
    "        return 0, False, {}\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.elapsed_steps += 1\n",
    "        \n",
    "        assert self.action_space.contains(action), \"%r (%s) invalid\" % (action, type(action))\n",
    "        \n",
    "        rs_action = copy.deepcopy(action)\n",
    "        # Scale action\n",
    "        rs_action = np.multiply(rs_action, self.action_range)\n",
    "        # Polar to Cartesian\n",
    "        x, y = polar_to_cartesian_2d(rs_action[0], rs_action[1])\n",
    "        rs_action = [x, y, rs_action[2]]\n",
    "        # Transformate coordinates of agent frame to map frame\n",
    "        rs_action = transform_2d(rs_action[0], rs_action[1], rs_action[2], *self.agent_pose)\n",
    "        \n",
    "        # Send action to Robot Server\n",
    "        if not self.client.send_action(rs_action.tolist()):\n",
    "            raise RobotServerError(\"send_action\")\n",
    "        \n",
    "        # Get state from Robot Server\n",
    "        rs_state = self.client.get_state_msg().state\n",
    "        # Convert the state from Robot Server format to environment format\n",
    "        self.state = self._robot_server_state_to_env_state(rs_state)\n",
    "        # Set agent_pose in map frame\n",
    "        self.agent_pose = polar_to_cartesian_2d(\n",
    "            self.state['agent_pose'][0],\n",
    "            self.state['agent_pose'][1],\n",
    "            self.state['agent_pose'][2],\n",
    "            *self.start_frame\n",
    "        )\n",
    "        \n",
    "        # Check if the environment state is contained in the observation space\n",
    "        if not self.observation_space.contains(self.state):\n",
    "            raise InvalidStateError()\n",
    "        \n",
    "        # Assign reward\n",
    "        reward, done, info = self._reward(rs_state=rs_state, action=action)\n",
    "\n",
    "        return self.state, reward, done, info\n",
    "    \n",
    "    def render(self):\n",
    "        pass\n",
    "        \n",
    "    def _get_env_state_len(self) -> int:\n",
    "        ## State include occupancy grid data and mir pose [x,y,yaw] in map frame \n",
    "        map_data = [0] * self.map_size**2\n",
    "        r_theta_yaw = [0.0, 0.0, 0.0]\n",
    "\n",
    "        env_state = map_data + r_theta_yaw\n",
    "        \n",
    "        return len(env_state)\n",
    "    \n",
    "    def _get_robot_server_state_len(self) -> int:\n",
    "#         map_size = [0]\n",
    "#         map_data = [0] * self.map_size**2\n",
    "#         map_data_trueth = [0] * self.map_size**2\n",
    "#         agent_pose = [0] * 3\n",
    "#         agent_twist = [0] * 2\n",
    "#         is_collision = [0]\n",
    "#         is_change_room = [0]\n",
    "#         is_change_pose = [0]\n",
    "#         room_generator_param = [0] * 8\n",
    "        \n",
    "#         rs_state = map_size + map_data + map_data_trueth + agent_pose + agent_twist + is_collision \\\n",
    "#                     + is_change_room + is_change_pose + room_generator_param\n",
    "        \n",
    "        return self.map_size**2 + 17\n",
    "    \n",
    "    def _robot_server_state_to_env_state(self, rs_state):\n",
    "        map_state_len = (self.map_size**2)*2\n",
    "        pose = rs_state[map_state_len+1 : map_state_len+4]\n",
    "        odom_x, odom_y, yaw = transform_2d(pose[0], pose[1], pose[2], *self.start_frame)\n",
    "        polar_r, polar_theta = utils.cartesian_to_polar_2d(x_target=odom_x, y_target=odom_y)\n",
    "        \n",
    "        # Normalize to +/- pi\n",
    "        polar_theta = utils.normalize_angle_rad(polar_theta)\n",
    "        \n",
    "#         state = np.concatenate([rs_state[1:self.map_size**2], [polar_r, polar_theta, yaw]])\n",
    "        \n",
    "        state = {\n",
    "            'occupancy_grid': np.array(rs_state[1:self.map_size**2]),\n",
    "            'agent_pose': np.array([polar_r, polar_theta, yaw])\n",
    "        }\n",
    "\n",
    "        return state\n",
    "    \n",
    "    def _get_observation_space(self):\n",
    "        occupancy_grid_space = spaces.Box(low=0, high=256, shape=(self.map_size**2,), dtype=np.int16)\n",
    "        \n",
    "        min_polar_r = 0\n",
    "        max_polar_r = np.inf\n",
    "        min_polar_theta = -np.pi\n",
    "        max_polar_theta = np.pi\n",
    "        min_yaw = 0\n",
    "        max_yaw = np.pi*2\n",
    "        \n",
    "        min_pose_obs = np.array([min_polar_r, min_polar_theta, min_yaw])\n",
    "        max_pose_obs = np.array([max_polar_r, max_polar_theta, max_yaw])\n",
    "        agent_pose_space = spaces.Box(low=min_pose_obs, high=max_pose_obs)\n",
    "        \n",
    "        observation_space = spaces.Dict({\n",
    "            'occupancy_grid': occupancy_grid_space,\n",
    "            'agent_pose': agent_pose_space,\n",
    "        })\n",
    "        \n",
    "        return observation_space\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "soviet-alpha",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[131  49  19  99  68 119 196 113 145 125   9  40  14 131  99 207  67 111\n",
      " 160  58  62 111  34 205 194 180 246 144 238 212 188 196 104  21 158  36\n",
      " 122 130  29  34  18 141 235 106 145 190 185  74 100 146  86  26 232  50\n",
      " 189  27  67  83  15  79  36 170 197 101 124 130 233 256  63 204 232 245\n",
      " 145   8 144 207 124  59 115 144  69  99 130  58  88 250 250 236 129 241\n",
      " 256  17  14 137 234 242  34 149 174 150  76 228  57 219 170 196 197 132\n",
      " 201 117 236 105 114 237 109  62 226 102 108 224 123 228 146 209  59  94\n",
      " 203 243 210 190   3 212 188 203 104 211  83 197  61 130 235 229  26 249\n",
      " 143 236 213   4  90 202 228 181 200 239 109 145  92  91  39 256  94  95\n",
      " 239 183 177 229  31 143 175 139  45 106 159 249 222  68  89  41  68 148\n",
      " 217  92 245  27 199 246  40  20 185  10  81 110  30  83 186 183  90  39\n",
      " 159  34 185 151 101  91  61 115  60  63  96  91 116 174  17  82 175 103\n",
      " 147 205 245  49 219  68 177 153 151 255  21 162 200 227  45 171 129 103\n",
      " 175 113 142 140 155 223 142 114 216  49  33 123 204  53  16 179 185 110\n",
      " 167 247  12  66]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'asdf': 1}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gym import spaces\n",
    "import numpy as np\n",
    "\n",
    "b = spaces.Box(low=0, high=256, dtype=np.int16, shape=(256,))\n",
    "print(b.sample())\n",
    "{'asdf':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "authorized-chart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.4887629,  2.300122 , 31.641535 ], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spaces.Box(low=np.array([1,1,1]), high=np.array([3,3,100])).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-suicide",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-special",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
