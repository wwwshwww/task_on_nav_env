{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "extraordinary-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import robo_gym\n",
    "from robo_gym.wrappers.exception_handling import ExceptionHandling\n",
    "import numpy as np\n",
    "import pfrl\n",
    "import torch\n",
    "from torch import distributions, nn\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "opposed-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrapPyTorch(gym.ObservationWrapper):\n",
    "    def __init__(self, env=None):\n",
    "        super(WrapPyTorch, self).__init__(env)\n",
    "        obs_shape = self.observation_space\n",
    "        agent_pose = env.observation_space['agent_pose']\n",
    "        occupancy_grid = env.observation_space['occupancy_grid']\n",
    "        self.map_size = int(occupancy_grid.shape[0] ** (1/2))\n",
    "        \n",
    "        agent_pose_space = spaces.Box(\n",
    "            low=np.expand_dims(agent_pose.low, axis=0),\n",
    "            high=np.expand_dims(agent_pose.high, axis=0),\n",
    "            shape=(1, agent_pose.shape[0]),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        occupancy_grid_space = spaces.Box(\n",
    "            low=occupancy_grid.low[0],\n",
    "            high=occupancy_grid.high[0],\n",
    "            shape=(1, self.map_size, self.map_size),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        \n",
    "        self.observation_space = spaces.Tuple((occupancy_grid_space, agent_pose_space))\n",
    "    \n",
    "    def observation(self, observation):\n",
    "        map_img = observation['occupancy_grid'].reshape((self.map_size, self.map_size)).T\n",
    "        occupancy_grid = np.expand_dims(map_img, axis=0)\n",
    "        agent_pose = observation['agent_pose']\n",
    "        return (occupancy_grid, agent_pose)\n",
    "    \n",
    "    def reset(self, **kwargs):\n",
    "        return self.observation(self.env.reset(**kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prepared-graphics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new Robot Server | Tentative 1\n",
      "<class 'server_manager_pb2.RobotServer'>\n",
      "True \n",
      "Successfully started Robot Server at localhost:56335\n",
      "Resetting env... [room: True, pose: True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         ...,\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.]]], dtype=float32),\n",
       " array([ 4.4754521e-16, -9.9227786e-01,  1.2403473e-01,  0.0000000e+00,\n",
       "         1.0000000e+00], dtype=float32))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_machine_ip = 'localhost' # or other machine 'xxx.xxx.xxx.xxx'\n",
    "\n",
    "# initialize environment\n",
    "env = gym.make('CubeRoomOnNavigationStack-v0', ip=target_machine_ip, gui=True)\n",
    "\n",
    "env = ExceptionHandling(env)\n",
    "env = WrapPyTorch(env)\n",
    "state = env.reset(**{'new_room': True, 'new_agent_pose': True})\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "monetary-coating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timelimit: \t500\n",
      "obs_space: \tTuple(Box(-1.0, 100.0, (1, 128, 128), float32), Box(-1.0, inf, (1, 5), float32)) \n",
      "action_space: \tBox(-1.0, 1.0, (3,), float32)\n",
      "obs_map_size: \t16384 \n",
      "obs_pose_size: \t5\n",
      "action_size: \t3\n"
     ]
    }
   ],
   "source": [
    "timestep_limit = env.spec.max_episode_steps\n",
    "obs_space = env.observation_space\n",
    "action_space = env.action_space\n",
    "obs_map_size = obs_space[0].low.size\n",
    "obs_pose_size = obs_space[1].low.size\n",
    "action_size = action_space.low.size\n",
    "\n",
    "print(f'timelimit: \\t{timestep_limit}')\n",
    "print(f'obs_space: \\t{obs_space} \\naction_space: \\t{action_space}')\n",
    "print(f'obs_map_size: \\t{obs_map_size} \\nobs_pose_size: \\t{obs_pose_size}')\n",
    "print(f'action_size: \\t{action_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "champion-calendar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         ...,\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.],\n",
       "         [-1., -1., -1., ..., -1., -1., -1.]]], dtype=float32),\n",
       " array([0.00929746, 0.6262265 , 0.7796412 , 0.99850106, 0.05473227],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# env.reset(new_room=False, new_agent_pose=True)\n",
    "state, _, _, _ = env.step([0,0,0.5])\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pharmaceutical-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_size_out(size, kernel_size=5, stride=2):\n",
    "    return (size - (kernel_size - 1) - 1) // stride + 1\n",
    "        \n",
    "def make_conv2d_layer(width, height):\n",
    "    convW = conv2d_size_out(width, 4, 4) # 128 -> 32\n",
    "    convW = conv2d_size_out(convW, 4, 4) # 32 -> 8\n",
    "    convW = conv2d_size_out(convW, 3, 1) # 8 -> 6\n",
    "\n",
    "    convH = conv2d_size_out(height, 4, 4)\n",
    "    convH = conv2d_size_out(convH, 4, 4)\n",
    "    convH = conv2d_size_out(convH, 3, 1)\n",
    "\n",
    "    linear_input_size = convW * convH * 64\n",
    "    print('size:', linear_input_size)\n",
    "\n",
    "    # RGB Image tensor as input\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(1, 32, kernel_size=4,stride=4),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(32, 64, kernel_size=4, stride=4),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(64, 64, kernel_size=3,stride=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(),\n",
    "    ), linear_input_size\n",
    "\n",
    "def make_linear_layer(linear_input_size, out_size):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(linear_input_size, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, out_size),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "structured-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squashed_diagonal_gaussian_head(x):\n",
    "    assert x.shape[-1] == action_size * 2\n",
    "    mean, log_scale = torch.chunk(x, 2, dim=1)\n",
    "    log_scale = torch.clamp(log_scale, -20.0, 2.0)\n",
    "    var = torch.exp(log_scale * 2)\n",
    "    base_distribution = distributions.Independent(\n",
    "        distributions.Normal(loc=mean, scale=torch.sqrt(var)), 1\n",
    "    )\n",
    "    # cache_size=1 is required for numerical stability\n",
    "    return distributions.transformed_distribution.TransformedDistribution(\n",
    "        base_distribution, [distributions.transforms.TanhTransform(cache_size=1)]\n",
    "    )\n",
    "\n",
    "# def extract_obs(obs):\n",
    "#     occupancy_grid_batch = torch.tensor([s['occupancy_grid'] for s in obs])\n",
    "#     agent_pose_batch = torch.tensor([s['agent_pose'] for s in state])\n",
    "#     return occupancy_grid_batch, agent_pose_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "medium-evans",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128)\n",
      "size: 2304\n"
     ]
    }
   ],
   "source": [
    "class PolicyFunction(nn.Module):\n",
    "    def __init__(self, width, height, pose_size, action_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # RGB Image tensor as input\n",
    "        self.selectTrackFeatures, self.linear_input_size = make_conv2d_layer(width, height)\n",
    "        self.fc1 = make_linear_layer(self.linear_input_size + pose_size, action_size*2)\n",
    "    \n",
    "    def forward(self, state):\n",
    "        x = self.selectTrackFeatures(state[0])\n",
    "#         print(x.shape, state[1].shape)\n",
    "        x = torch.cat((x, state[1]), axis=-1)\n",
    "        x = self.fc1(x)\n",
    "        return squashed_diagonal_gaussian_head(x)\n",
    "\n",
    "obs_map_shape = obs_space[0].low.shape\n",
    "print(obs_map_shape)\n",
    "policy = PolicyFunction(obs_map_shape[1], obs_map_shape[2], obs_pose_size, action_size)\n",
    "policy_optimizer = torch.optim.Adam(policy.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "offshore-dynamics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 2304\n",
      "size: 2304\n"
     ]
    }
   ],
   "source": [
    "class QFunction(nn.Module):\n",
    "    def __init__(self, width, height,pose_size, action_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # RGB Image tensor as input\n",
    "        self.selectTrackFeatures, self.linear_input_size = make_conv2d_layer(width, height)\n",
    "        self.fc1 = make_linear_layer(self.linear_input_size + pose_size + action_size, 1)\n",
    "    \n",
    "    def forward(self, state_and_action):\n",
    "        state = state_and_action[0]\n",
    "        occupancy_vector = self.selectTrackFeatures(state[0])\n",
    "        x = torch.cat((occupancy_vector, state[1], state_and_action[1]), axis=-1)\n",
    "        return self.fc1(x)\n",
    "\n",
    "q_func1 = QFunction(obs_map_shape[1], obs_map_shape[2], obs_pose_size, action_size)\n",
    "q_func2 = QFunction(obs_map_shape[1], obs_map_shape[2], obs_pose_size, action_size)\n",
    "q_func1_optimizer = torch.optim.Adam(q_func1.parameters(), lr=3e-4)\n",
    "q_func2_optimizer = torch.optim.Adam(q_func2.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "coupled-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbuf = pfrl.replay_buffers.ReplayBuffer(10 ** 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "monetary-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def burnin_action_func():\n",
    "    \"\"\"Select random actions until model is updated one or more times.\"\"\"\n",
    "    return np.random.uniform(action_space.low, action_space.high).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "romance-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.99\n",
    "replay_start_size = 10000\n",
    "gpu = -1\n",
    "batch_size = 256\n",
    "entropy_target = -action_size\n",
    "temperature_optimizer_lr = 3e-4\n",
    "\n",
    "agent = pfrl.agents.SoftActorCritic(\n",
    "    policy,\n",
    "    q_func1,\n",
    "    q_func2,\n",
    "    policy_optimizer,\n",
    "    q_func1_optimizer,\n",
    "    q_func2_optimizer,\n",
    "    rbuf,\n",
    "    gamma=gamma,\n",
    "    replay_start_size=replay_start_size,\n",
    "    gpu=gpu,\n",
    "    minibatch_size=batch_size,\n",
    "    burnin_action_func=burnin_action_func,\n",
    "    entropy_target=entropy_target,\n",
    "    temperature_optimizer_lr=temperature_optimizer_lr,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 10\n",
    "max_episode_len = 500\n",
    "\n",
    "for i in range(1, n_episodes + 1):\n",
    "    obs = env.reset(new_room=False, new_agent_pose=True)\n",
    "    R = 0  # return (sum of rewards)\n",
    "    t = 0  # time step\n",
    "    while True:\n",
    "        # Uncomment to watch the behavior in a GUI window\n",
    "        # env.render()\n",
    "        action = agent.act(obs)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        R += reward\n",
    "        t += 1\n",
    "        reset = t == max_episode_len\n",
    "        agent.observe(obs, reward, done, reset)\n",
    "        # print(f\"action: {action}, reward: {reward}\")\n",
    "        if done or reset:\n",
    "            break\n",
    "    if i % 10 == 0:\n",
    "        print('episode:', i, 'R:', R, '\\nstatistics:', agent.get_statistics())\n",
    "\n",
    "print('Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-raleigh",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbuf.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-arnold",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
